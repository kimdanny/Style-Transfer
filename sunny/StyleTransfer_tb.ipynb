{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StyleTransfer_tb.ipynb","version":"0.3.2","provenance":[{"file_id":"1m9rZ7wipvLxx_9_8ASWziq8_GtKAEOOd","timestamp":1565590962912},{"file_id":"1LMIo6pAXOR9uBzwEPkiQ38yeq3M1eCxE","timestamp":1565241268575}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QC-KWsbUTlYg","colab_type":"code","outputId":"d856d387-0e02-4af7-c806-98b646f4d1ec","executionInfo":{"status":"ok","timestamp":1565736593641,"user_tz":-540,"elapsed":2873,"user":{"displayName":"장지선","photoUrl":"","userId":"13628801302771359182"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# Imports\n","import numpy as np\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","from tqdm import tqdm\n","import csv\n","from datetime import datetime\n","\n","from keras import backend\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","\n","from scipy.optimize import fmin_l_bfgs_b\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NbQT7ITK4OrR","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFqsO1mRVPQ6","colab_type":"code","colab":{}},"source":["# Hyperparams\n","ITERATIONS = 20\n","CHANNELS = 3\n","IMAGE_SIZE = 500\n","IMAGE_WIDTH = IMAGE_SIZE\n","IMAGE_HEIGHT = IMAGE_SIZE\n","IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n","CONTENT_WEIGHT = 0.02 #default = 0.02\n","STYLE_WEIGHT = 0 #default = 4.5\n","TOTAL_VARIATION_WEIGHT = 0.995 #default = 0.995 \n","TOTAL_VARIATION_LOSS_FACTOR = 1.25 #default = 1.25"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0SWjbpcVSs1","colab_type":"code","colab":{}},"source":["# Paths\n","input_image_path = \"drive/My Drive/AIschool Team4/장지선/input.png\"\n","style_image_path = \"drive/My Drive/AIschool Team4/장지선/style.png\"\n","output_image_path = \"drive/My Drive/AIschool Team4/장지선/output.png\"\n","# combined_image_path = \"drive/My Drive/AIschool Team4/장지선/combined.png\"\n","\n","# San Francisco\n","san_francisco_image_path = \"https://www.economist.com/sites/default/files/images/print-edition/20180602_USP001_0.jpg\"\n","\n","# Warsaw by Tytus Brzozowski, http://t-b.pl\n","tytus_image_path = \"http://meetingbenches.com/wp-content/flagallery/tytus-brzozowski-polish-architect-and-watercolorist-a-fairy-tale-in-warsaw/tytus_brzozowski_13.jpg\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vu4cWtv_VmlC","colab_type":"code","colab":{}},"source":["#Input visualization \n","input_image = Image.open(BytesIO(requests.get(san_francisco_image_path).content))\n","input_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n","input_image.save(input_image_path)\n","input_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5U3m_s_VoCQ","colab_type":"code","colab":{}},"source":["# Style visualization \n","style_image = Image.open(BytesIO(requests.get(tytus_image_path).content))\n","style_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n","style_image.save(style_image_path)\n","style_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"40MEP4WoVqNV","colab_type":"code","colab":{}},"source":["# Data normalization and reshaping from RGB to BGR\n","input_image_array = np.asarray(input_image, dtype=\"float32\")\n","input_image_array = np.expand_dims(input_image_array, axis=0)\n","input_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n","input_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n","input_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n","input_image_array = input_image_array[:, :, :, ::-1]\n","\n","style_image_array = np.asarray(style_image, dtype=\"float32\")\n","style_image_array = np.expand_dims(style_image_array, axis=0)\n","style_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n","style_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n","style_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n","style_image_array = style_image_array[:, :, :, ::-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnb_kSD0VrxR","colab_type":"code","colab":{}},"source":["# Model\n","input_image = backend.variable(input_image_array)\n","style_image = backend.variable(style_image_array)\n","combination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3))\n","\n","input_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\n","model = VGG16(input_tensor=input_tensor, include_top=False)\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCUCCUugVtZr","colab_type":"code","colab":{}},"source":["def content_loss(content, combination):\n","    return backend.sum(backend.square(combination - content))\n","  \n","def gram_matrix(x):\n","    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n","    gram = backend.dot(features, backend.transpose(features))\n","    return gram\n","\n","def compute_style_loss(style, combination):\n","    style = gram_matrix(style)\n","    combination = gram_matrix(combination)\n","    size = IMAGE_HEIGHT * IMAGE_WIDTH\n","    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n","  \n","def total_variation_loss(x):\n","    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n","    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n","    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n","\n","def evaluate_loss_and_gradients(x):\n","    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n","    outs = backend.function([combination_image], outputs)([x])\n","    loss = outs[0]\n","    gradients = outs[1].flatten().astype(\"float64\")\n","    return loss, gradients\n","  \n","def visualx(x):\n","    x = x.copy()\n","    x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n","    x = x[:, :, ::-1]\n","    x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n","    x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n","    x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n","    x = np.clip(x,0,255).astype('uint8')\n","    output_image = Image.fromarray(x)\n","    return output_image\n","    \n","    \n","def toCSV(csv_col, dict_):\n","    file = open('drive/My Drive/AIschool Team4/장지선/loss.csv', 'w', newline = '')\n","    csvfile = csv.DictWriter(file, fieldnames=csv_col)\n","    for row in dict_:\n","        csvfile.writerow(row)\n","    file.close()\n","\n","class Evaluator:\n","\n","    def loss(self, x):\n","        loss, gradients = evaluate_loss_and_gradients(x)\n","        self._gradients = gradients\n","        return loss\n","\n","    def gradients(self, x):\n","        return self._gradients"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdALRe8E_BO3","colab_type":"code","colab":{}},"source":["conv_layer = []\n","for layer in model.layers:\n","    conv_layer.append(layer.name)\n","    print(layer.name)\n","del conv_layer[0]\n","conv_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVSGLH2g34DC","colab_type":"code","colab":{}},"source":["!ls drive/My\\ Drive/AIschool\\ Team4/장지선/output/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqbBwrRF-4Ra","colab_type":"code","colab":{}},"source":["layers = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","conv_layer = ['block2_conv2','block3_conv1']\n","\n","num =0\n","csv_col = ['block', 'iteration', 'loss']\n","dict_data = []\n","\n","for i in tqdm(conv_layer):\n","#     merged_summary = tf.summary.merge_all()\n","    logdir = 'drive/My Drive/AIschool Team4/장지선/logs'\n","    file_writer = tf.contrib.summary.create_file_writer(logdir, name=datetime.now().strftime('%Y%m%d-%H%M%S'))\n","#     sess.run(tf.global_variables_initializer())\n","\n","    content_layer = str(i)\n","    num += 1\n","    print(\"trial\",num,content_layer)\n","    layer_features = layers[content_layer]\n","    content_image_features = layer_features[0, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","\n","    loss = backend.variable(0.)\n","    loss = loss + CONTENT_WEIGHT * content_loss(content_image_features,\n","                                          combination_features)\n","\n","    style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n","\n","    for layer_name in style_layers:\n","        layer_features = layers[layer_name]\n","        style_features = layer_features[1, :, :, :]\n","        combination_features = layer_features[2, :, :, :]\n","        style_loss = compute_style_loss(style_features, combination_features)\n","        loss = loss + (STYLE_WEIGHT / len(style_layers)) * style_loss\n","\n","\n","    loss = loss + TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)\n","\n","    outputs = [loss]\n","    outputs += backend.gradients(loss, combination_image)\n","\n","    evaluator = Evaluator()\n","\n","    x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n","\n","    for i in tqdm(range(ITERATIONS)):\n","        x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n","        canvas = visualx(x)\n","        path = 'drive/My Drive/AIschool Team4/장지선/ParameterChange/outputs'+content_layer+'_total0.998_iteration_'+str(i)+'.png'\n","        canvas.save(str(path))\n","        dict_data.append({csv_col[0]:content_layer ,csv_col[1]:i ,csv_col[2]:loss })\n","        xx = x.copy()\n","        xx = xx.reshape(IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n","        xx = tf.expand_dims(xx, axis=0)\n","        xx = tf.transpose(xx, perm=[3,1,2,0])\n","        tf.summary.image('input',xx, 10)\n","\n","        print(\"Iteration %d completed with loss %d\" % (i, loss))\n","            \n","toCSV(csv_col, dict_data) \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FfF0sHHRV6dF","colab_type":"code","colab":{}},"source":["# # Visualizing combined results\n","# combined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\n","# x_offset = 0\n","# for image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n","#     combined.paste(image, (x_offset, 0))\n","#     x_offset += IMAGE_WIDTH\n","# combined.save(combined_image_path)\n","# combined"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8F3PFeSI71D","colab_type":"code","colab":{}},"source":["crop = Image.new(\"RGB\",(IMAGE_WIDTH, IMAGE_HEIGHT))\n","area = (50,50,200,200)\n","for i in conv_layer:\n","    imgs_path = 'drive/My Drive/AIschool Team4/장지선/output/'+i+'/content_iteration_19.png'\n","    crop = Image.open(imgs_path)\n","    crop = crop.crop(area)\n","    crop.save('drive/My Drive/AIschool Team4/장지선/output/'+i+'/crop_withtotal_19.png')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lijk-svII7qT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}