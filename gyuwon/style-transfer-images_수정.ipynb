{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"style-transfer-images_수정.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/AI-School-Team4/Style-Transfer/blob/master/style-transfer.ipynb","timestamp":1565415869279}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-10T04:00:10.231729Z","start_time":"2019-08-10T04:00:10.208274Z"},"_uuid":"9bab7d1fb54866d80f6fc3127ccf428772c5ab7d","colab_type":"code","id":"XGDbz8e1Cl96","outputId":"68a1cef2-6e49-42fe-8365-eb0f32ef5920","executionInfo":{"status":"ok","timestamp":1567569491344,"user_tz":-540,"elapsed":9787,"user":{"displayName":"이규원","photoUrl":"","userId":"04689330749496000574"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["# Imports\n","import numpy as np\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import matplotlib.pyplot as pl\n","\n","from keras import backend\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg19 import VGG19\n","\n","from scipy.optimize import fmin_l_bfgs_b\n","        \n","import tensorflow as tf\n","assert tf.__version__[0] == '1', 'tensorflow version 1 is required'\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PXWvu81hewlQ","colab_type":"code","colab":{}},"source":["import datetime"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXBACPtuQ0u5","colab_type":"code","colab":{}},"source":["#!ls -al drive/'My Drive'/'AIschool Team4'/이규원/input_image\n","#!ls -al drive/'My Drive'/'AIschool Team4'/이규원/style_image\n","#!cp -r drive/'My Drive'/'AIschool Team4'/이규원/기본/* drive/'My Drive'/'AIschool Team4'/이규원/\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-10T04:00:12.497407Z","start_time":"2019-08-10T04:00:12.485932Z"},"_uuid":"48f3a236922c8a1d85fdc6efd68669eaee8ff919","colab_type":"code","id":"MtSoMDOdCl-B","colab":{}},"source":["# Hyperparams\n","ITERATIONS = 20\n","CHANNELS = 3\n","IMAGE_SIZE = 500\n","IMAGE_WIDTH = IMAGE_SIZE\n","IMAGE_HEIGHT = IMAGE_SIZE\n","IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n","CONTENT_WEIGHT = 0.02 # default = 0.02\n","STYLE_WEIGHT = 4.5    # default = 4.5\n","TOTAL_VARIATION_WEIGHT = 0.995 # default = 0.995\n","TOTAL_VARIATION_LOSS_FACTOR = 1.25 # default = 1.25"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-10T04:27:27.800259Z","start_time":"2019-08-10T04:27:27.761333Z"},"colab_type":"code","id":"pJTEjyW9Cl-Z","colab":{}},"source":["'''define functions'''\n","### I don't understand why backend is used.\n","\n","def load_img(path, IMAGE_WIDTH, IMAGE_HEIGHT):\n","    image = Image.open(path)\n","    image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n","    image.save(path)\n","    return image\n","\n","def data_norm_reshap(image):\n","    image_array = np.asarray(image, dtype=\"float32\") # shape == (500, 500, 3)\n","    image_array = np.expand_dims(image_array, axis=0) # shape == (1, 500, 500, 3)\n","\n","    image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2] # normalization\n","    image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n","    image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n","    image_array = image_array[:, :, :, ::-1] # reshaping\n","  \n","    return image_array\n","\n","def mk_model(input_image_array, style_image_array, IMAGE_HEIGHT, IMAGE_SIZE):\n","    input_image = backend.variable(input_image_array) # content image variable | shape == (1, 500, 500, 3)\n","    style_image = backend.variable(style_image_array) # style image variable | shape == (1, 500, 500, 3)\n","    combination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3)) # placeholder..? | shape == (1, 500, 500, 3)\n","\n","    input_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\n","#                      concatenated in order of content(0), style(1), noise(2)\n","#   model = VGG16(input_tensor=input_tensor, include_top=False) # WARNING : VGG16\n","    model = VGG19(input_tensor=input_tensor, include_top=False)\n","    return input_image, style_image, combination_image, model\n","\n","def content_loss(content, combination):\n","    return backend.sum(backend.square(combination - content))\n","\n","def gram_matrix(x):\n","    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n","    gram = backend.dot(features, backend.transpose(features))\n","    return gram\n","\n","def compute_style_loss(style, combination):\n","    style = gram_matrix(style)\n","    combination = gram_matrix(combination)\n","    size = IMAGE_HEIGHT * IMAGE_WIDTH\n","    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n","\n","def total_variation_loss(x):\n","    '''\n","    x : combination_image (== noise image)\n","    combination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3)) # placeholder..? | shape == (1, 500, 500, 3)\n","    what is placeholder?\n","    '''\n","    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n","    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n","    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n","\n","def evaluate_loss_and_gradients(x):\n","    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n","    outs = backend.function([combination_image], outputs)([x]) ### backend.function..?\n","    loss = outs[0]\n","    gradients = outs[1].flatten().astype(\"float64\")\n","    return loss, gradients\n","\n","class Evaluator:\n","\n","    def loss(self, x):\n","        loss, gradients = evaluate_loss_and_gradients(x)\n","        self._gradients = gradients\n","        return loss\n","\n","    def gradients(self, x):\n","        return self._gradients\n","\n","def visualx(x):\n","    '''x : normalized numpy array'''\n","    x = x.copy()\n","    x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n","    x = x[:, :, ::-1]\n","    x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n","    x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n","    x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n","    x = np.clip(x, 0, 255).astype(\"uint8\")\n","    output_image = Image.fromarray(x)\n","    return output_image\n","  \n","def noise(IMAGE_HEIGHT, IMAGE_WIDTH, noise_image_path):\n","    x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128. # noise image??\n","    noise_image = visualx(x)\n","    noise_image.save(noise_image_path)\n","    return x, noise_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-08-10T04:29:55.891486Z","start_time":"2019-08-10T04:29:55.878514Z"},"_uuid":"f86b73d5096c14604fb0db7b4bf5f906248a5b6d","colab_type":"code","id":"VAP2cfGkCl-F","outputId":"1d9c6b84-e2b0-43a1-f834-65b715da7cd2","executionInfo":{"status":"ok","timestamp":1566225466906,"user_tz":-540,"elapsed":3395356,"user":{"displayName":"이규원","photoUrl":"","userId":"04689330749496000574"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Paths\n","#input_image_path = \"drive/My Drive/Alschool Team4/이규원/input_image/\"\n","#style_image_path = \"drive/My Drive/Alschool Team4/이규원/style_image/\"\n","\n","input_image_name = ['statue-of-liberty']                    \n","style_image_name = ['bridg', 'evening', 'flowers', 'planet', 'post-impressionist']#png = '.png'\n","\n","\n","for input in input_image_name:\n","  for style in style_image_name:\n","    \n","    input_image_path = 'drive/My Drive/AIschool Team4/이규원/input_image/'+input+'.png'\n","    style_image_path = 'drive/My Drive/AIschool Team4/이규원/style_image/'+style+'.png'\n","    output_image_path = 'drive/My Drive/AIschool Team4/이규원/output_image/'+style+'ed_'+input+'.png'\n","    combined_image_path = 'drive/My Drive/AIschool Team4/이규원/'+'combined_'+style+'ed_'+input+'.png'\n","\n","    folder_name = style+'ed_'+input\n","    !mkdir 'drive/My Drive/AIschool Team4/이규원/canvas_original_100/'$folder_name\n","    \n","    \n","    canvas_path = 'drive/My Drive/AIschool Team4/이규원/canvas_original_100/'+folder_name+'/canvas_iter{}.png'\n","    noise_image_path = 'drive/My Drive/AIschool Team4/이규원/canvas_original_100/'+folder_name+'/noise.png'\n","  \n","    C_path = input_image_path\n","    S_path = style_image_path\n","  \n","    print('***************', style+'ed_'+input, '***************', datetime.datetime.now())\n","  \n","    input_image = load_img(C_path, IMAGE_HEIGHT, IMAGE_WIDTH)\n","    style_image = load_img(S_path, IMAGE_HEIGHT, IMAGE_WIDTH)\n","    \n","    input_image_array = data_norm_reshap(input_image)\n","    style_image_array = data_norm_reshap(style_image)\n","    input_image, sytle_image, combination_image, model = mk_model(input_image_array, style_image_array, IMAGE_HEIGHT, IMAGE_SIZE)\n","  \n","    layers = dict([(layer.name, layer.output) for layer in model.layers])\n","    content_layer = \"block2_conv2\" # which layer to be used for content_loss\n","    layer_features = layers[content_layer] # output of content_layer\n","    content_image_features = layer_features[0, :, :, :] # feature map of content image in block2_conv2 (== content_layer)\n","    combination_features = layer_features[2, :, :, :] # feature map of noise iamge in block2_conv2 (== content_layer)\n","    loss = backend.variable(0.)\n","    loss += CONTENT_WEIGHT * content_loss(content_image_features, combination_features)\n","  \n","    style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n","    for layer_name in style_layers:\n","        layer_features = layers[layer_name] # output of style_layers\n","        style_features = layer_features[1, :, :, :] # feature map of style image\n","        combination_features = layer_features[2, :, :, :] # feature map of noise image\n","        style_loss = compute_style_loss(style_features, combination_features)\n","        loss += (STYLE_WEIGHT / len(style_layers)) * style_loss\n","    \n","    loss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)\n","\n","    outputs = [loss] ### what's this?\n","    outputs += backend.gradients(loss, combination_image)\n","  \n","    evaluator = Evaluator()\n","  \n","    x, noise_image = noise(IMAGE_HEIGHT, IMAGE_WIDTH, noise_image_path)\n","    \n","    for i in range(ITERATIONS):\n","        x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n","        canvas = visualx(x)\n","        canvas.save(canvas_path.format(i))\n","        print(\"Iteration %d completed with loss %d\" % (i, loss))\n","    \n","    x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n","    x = x[:, :, ::-1]\n","    x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n","    x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n","    x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n","    x = np.clip(x, 0, 255).astype(\"uint8\")\n","    output_image = Image.fromarray(x)\n","    output_image.save(output_image_path)\n","\n","    combined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\n","    x_offset = 0\n","    for image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n","        combined.paste(image, (x_offset, 0))\n","        x_offset += IMAGE_WIDTH\n","    combined.save(combined_image_path)\n","    print('***************', 'completed','***************')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘drive/My Drive/AIschool Team4/이규원/canvas_original_100/bridged_statue-of-liberty’: File exists\n","*************** bridged_statue-of-liberty *************** 2019-08-19 13:41:14.941269\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0819 13:41:16.814781 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0819 13:41:16.821798 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0819 13:41:16.825032 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0819 13:41:16.877082 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 7s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["W0819 13:41:25.752739 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0819 13:41:25.754156 140568526956416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0819 13:41:28.926808 140568526956416 variables.py:2429] Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n","W0819 13:41:29.193573 140568526956416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration 0 completed with loss 41186496512\n","Iteration 1 completed with loss 14795197440\n","Iteration 2 completed with loss 11052460032\n","Iteration 3 completed with loss 9755061248\n","Iteration 4 completed with loss 9094660096\n","Iteration 5 completed with loss 8496013312\n","Iteration 6 completed with loss 7974195200\n","Iteration 7 completed with loss 7404662784\n","Iteration 8 completed with loss 6812642816\n","Iteration 9 completed with loss 6177075200\n","Iteration 10 completed with loss 5718360576\n","Iteration 11 completed with loss 5197266432\n","Iteration 12 completed with loss 4801646592\n","Iteration 13 completed with loss 4458897920\n","Iteration 14 completed with loss 4204295680\n","Iteration 15 completed with loss 4012777984\n","Iteration 16 completed with loss 3847870208\n","Iteration 17 completed with loss 3700473088\n","Iteration 18 completed with loss 3586078720\n","Iteration 19 completed with loss 3491884288\n","*************** completed ***************\n","*************** eveninged_statue-of-liberty *************** 2019-08-19 13:52:03.503013\n","Iteration 0 completed with loss 61850767360\n","Iteration 1 completed with loss 33090181120\n","Iteration 2 completed with loss 23180353536\n","Iteration 3 completed with loss 18840137728\n","Iteration 4 completed with loss 17288255488\n","Iteration 5 completed with loss 16775762944\n","Iteration 6 completed with loss 16537011200\n","Iteration 7 completed with loss 16389507072\n","Iteration 8 completed with loss 16289097728\n","Iteration 9 completed with loss 16211650560\n","Iteration 10 completed with loss 16150686720\n","Iteration 11 completed with loss 16100630528\n","Iteration 12 completed with loss 16057285632\n","Iteration 13 completed with loss 16018934784\n","Iteration 14 completed with loss 15984793600\n","Iteration 15 completed with loss 15951452160\n","Iteration 16 completed with loss 15921350656\n","Iteration 17 completed with loss 15892851712\n","Iteration 18 completed with loss 15866426368\n","Iteration 19 completed with loss 15841705984\n","*************** completed ***************\n","*************** flowersed_statue-of-liberty *************** 2019-08-19 14:02:57.532997\n","Iteration 0 completed with loss 88729337856\n","Iteration 1 completed with loss 47290576896\n","Iteration 2 completed with loss 38487420928\n","Iteration 3 completed with loss 34563768320\n","Iteration 4 completed with loss 32001730560\n","Iteration 5 completed with loss 30275903488\n","Iteration 6 completed with loss 29064425472\n","Iteration 7 completed with loss 28097202176\n","Iteration 8 completed with loss 27354529792\n","Iteration 9 completed with loss 26816366592\n","Iteration 10 completed with loss 26385899520\n","Iteration 11 completed with loss 26030944256\n","Iteration 12 completed with loss 25741250560\n","Iteration 13 completed with loss 25498533888\n","Iteration 14 completed with loss 25278672896\n","Iteration 15 completed with loss 25083447296\n","Iteration 16 completed with loss 24924323840\n","Iteration 17 completed with loss 24785352704\n","Iteration 18 completed with loss 24667226112\n","Iteration 19 completed with loss 24565043200\n","*************** completed ***************\n","*************** planeted_statue-of-liberty *************** 2019-08-19 14:14:12.751291\n","Iteration 0 completed with loss 34538799104\n","Iteration 1 completed with loss 19719241728\n","Iteration 2 completed with loss 14051182592\n","Iteration 3 completed with loss 10362484736\n","Iteration 4 completed with loss 7927687168\n","Iteration 5 completed with loss 6431704064\n","Iteration 6 completed with loss 5612912640\n","Iteration 7 completed with loss 4932946432\n","Iteration 8 completed with loss 4552258048\n","Iteration 9 completed with loss 4253740288\n","Iteration 10 completed with loss 4003826688\n","Iteration 11 completed with loss 3809988864\n","Iteration 12 completed with loss 3659227904\n","Iteration 13 completed with loss 3539983872\n","Iteration 14 completed with loss 3418878464\n","Iteration 15 completed with loss 3321464320\n","Iteration 16 completed with loss 3239300096\n","Iteration 17 completed with loss 3171268096\n","Iteration 18 completed with loss 3106450944\n","Iteration 19 completed with loss 3051773184\n","*************** completed ***************\n","*************** post-impressionisted_statue-of-liberty *************** 2019-08-19 14:25:50.654925\n","Iteration 0 completed with loss 71130005504\n","Iteration 1 completed with loss 43593334784\n","Iteration 2 completed with loss 28408403968\n","Iteration 3 completed with loss 23020730368\n","Iteration 4 completed with loss 20895670272\n","Iteration 5 completed with loss 19511947264\n","Iteration 6 completed with loss 18648080384\n","Iteration 7 completed with loss 17985859584\n","Iteration 8 completed with loss 17488936960\n","Iteration 9 completed with loss 17149083648\n","Iteration 10 completed with loss 16896497664\n","Iteration 11 completed with loss 16668264448\n","Iteration 12 completed with loss 16445185024\n","Iteration 13 completed with loss 16282931200\n","Iteration 14 completed with loss 16122857472\n","Iteration 15 completed with loss 15993680896\n","Iteration 16 completed with loss 15905395712\n","Iteration 17 completed with loss 15799454720\n","Iteration 18 completed with loss 15716755456\n","Iteration 19 completed with loss 15653832704\n","*************** completed ***************\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l1hPAgEKWKuv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}